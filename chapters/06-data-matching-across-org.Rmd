# Data matching across organizations and agencies {#ch-dm-across-org}

\chaptermark{Data matching across organizations}

__Abstract__

\noindent

_Enter abstract here_

---

\vspace*{\fill}
\noindent
_Possibly insert citation here._
\newpage

## Introduction

What we know about technologies for identifying people is strongly related to how we know the devices and practices involved.[^paraphrase] For example, every year authorities identify millions of people crossing the EU external border; people migrating to and from the EU, visiting as tourists, or seeking asylum. To do this identification, authorities will link and cross-check personal data from various databases to help identify people. For instance, to verify identities for visa applications, to detect identity fraud by linking identities across national and international policing systems, or to match flight passengers' personal data against government watch lists. These processes play a role in furcating mobilities — speeding up, slowing down, excluding some forms of mobility [@sparkeNeoliberalNexusEconomy2006]. But, what do we know about the systems that progressively carry more weight in establishing someone's identity, and how do we know the technologies?

[^paraphrase]: In this sentence I paraphrase a more general insight of @pollockSoftwareOrganisationsBiography2009: 'What we know about technologies, their innovation processes and outcomes is closely bound up with how we know them.' (p. 51)

Researchers can bring in to focus a number of moments in the lifecycle of technologies of identification thus giving specific perspectives on the technologies and their related practices. Moving backwards in time we might focus on different moments and locales: from operation and maintenance of sociotechnical systems of identification to initial phases of their conception. At airports, for instance, we might observe the choreography required between border agents and devices to identify travellers with automated borders systems using their biometric passports [e.g., @lisleManyLivesBorder2019]. Shifting attention to back office systems supporting border management might foreground everyday activities to maintain and operate large information systems and difficulties of dealing with incomplete or inaccurate to identify persons [e.g., @bellanovaControllingSchengenInformation2020]. Or, the processes of developing systems could be traced by following actors and reviewing proposals: from initial steps policymaking in establishment of policy such as the EU 'smart borders' package [@bigoJusticeHomeAffairs2012a; @jeandesbozSmarteningBorderSecurity2016] to the design of a something like the EU Visa Information System [@glouftsiosDesigningDigitalBorders2019]. Selecting between one or more of these moments in the lifecycle of a sociotechnology of identification (e.g., planning, analysis, design, procurement, implementation, operation, maintenance) and disregarding others will unavoidably lead to partial descriptions [@pollockEInfrastructuresHowWe2010].

Those moments are not self-contained, but rather contain interconnected and contingent aspects of the lifecycle of sociotechnologies of identification. For example, research design focusing on practices of biometric identification might miss how various actors mediate and intertwine with identification, just as EU Member State fingerprinting software are made to comply with US standards [@pelizzaProcessingAlterityEnacting2019]. Alternatively, taking proposals and technical design specifications as a starting point of inquiry might miss the intricacies of adopting technologies to particular locales. Taking into account all moments and actors is of course impossible, so researchers need to weigh and make explicit their choices through an understanding of the field and the research objectives.

The choices researchers make can have real effects since it is by now widely accepted that research methods play an active role in bringing into being phenomena they set out to describe and discover [@lawEnactingSocial2004]. Methods can, according to this view, be thought of as devices that bring together bits and pieces of the world to enact certain realities. The question therefore has come to be in which 'ontological politics' (sic.) researchers are involved in and what realities they help make. There are, for instance, important reasons to make migrants' practices and experience a starting point to understand forms of discrimination and unpredictability ingrained in sociotechnologies of identification at the border. Yet, such focus also might make one oblivious to the fact that a small oligopoly of technology companies and IT consultancy companies are dominating the development of technologies for identifying people [@lemberg-pedersenPoliticalEconomyEntry2020; @jonesFundsFortressEurope2022]. There is thus always a risk to be, perhaps as Franz Kafka's protagonist K. in his novel _The Castle_, stuck outside _Fortress Europe_ without knowledge of its inner workings. At the same times, the tropes of fortification and securitization might obscure disparities between experiences at the border. If methods are not innocent, the choice of what to include in research designs is also political.

In this article I review strand of research that have scrutinized sociotechnologies of identification in EU migration and border control. While many scholars have highlighted materiality and performativity of devices and practices, they tend to stay rather implicit on their methodological choices in their accounts. I therefore compare these strands of research with principles and concepts formulated by approaches in STS which have provided suggestions to common research designs on how to best study complex data infrastructures, such as those involved in practices of identification. While those researchers have somewhat different aims in understanding sociotechnical change and innovation practices, I argue that their propositions provide useful heuristics to understand current (sometimes implicit) methodological choices in research on technologies of border and migration control. After reviewing related work, I reflect on these challenges with some of my fieldwork findings and by presenting a few key 'biographical moments' [@glaserBiographyAlgorithmPerforming2021] of a software package that is entangled in identification at EU and Member States. These moments are surely not aimed to provide a somehow better picture, but rather as examples of what can be gained by taking into account lesser known actors and aspects of the lifecycle of sociotechnologies of identification.

## Related work

Ongoing scholarly debates in the field of Science and Technology Studies (STS) about the intertwining of methods and outcome of investigations may have implications for research conducted on technologies at the border. Broadly speaking, the debate has called attention to a discrepancy between research designs concerned with sociotechnological and the knowledge that technologies are shaped, over time, in multiple context and by various actors [@hyysaloMethodMattersSocial2019; @silvastTheorymethodsPackagesScience2021]. On the whole, this scholarship asserts that many inquiries omit these insights on the multiple and contingent life of technologies by limited research designs, and provides recommendations for ameliorating research. This assessment is not insignificant, especially when combined with the insight that methods do not merely describe the world but are play a role in enacting particular realities [@lawEnactingSocial2004].

Several principles and guidelines can be deduced from this scholarship [@hyysaloMethodMattersSocial2019; @karastiStudyingInfrastructuringEthnographically2018; @silvastTheorymethodsPackagesScience2021], which can serve as heuristics to understand what is present and what is missing from debates on sociotechnologies of identification in border and migration management. To begin, technologies for identifying people at the border are part of larger data or infrastructures. As part of distributed infrastructures their development, deployment, use takes place within settings with many dimensions and interconnected actors which poses particular challenges on how to study these complex phenomena. One recurring recommendation is to focus on moments and sites where multiple of such actors affect each other. Ideally, research should then take account of sufficient of such moments to understand the extent of change across localities and temporalities, and to have accounts that take into account a diversity actors. Following this line of research, technologies are not assumed to be stable but are enacted differently across multiple contexts. For instance, the same biometric identification system deployed at an airport may not have the same meaning when deployed at a difficult land border.

For a number of years, researchers in fields such as migration and security studies, International Relations have drawn from concepts, theories, and methods from STS to study sociotechnologies of identification in border and migration control. The question remains of how these authors have integrated those same insights into their research problems and designs. Surveying the landscape of research on sociotechnologies of identification would help in identify prevailing problematizations of sociotechnologies of identification and the methodologies employed by researchers. As a representative case, I am especially interested research investigating the European information systems in the area of Justice and Home Affairs (JHA), and closely related developments. These include systems that, combined, contain millions of personal data on third country nationals to identify persons and control their movements to and within the European Union. As such, these JHA information systems have been widely researched from a multitude of angles.

### Differences and particularities in body of literature

Next to similarities, there are many distinctive features of research in the body of literature. In this section I will draw from the principles and guidelines deduced from STS scholarship and on how to study information infrastructures. These concepts can serve as heuristics to highlight key differences and particularities in literature on research related to the EU JHA information systems and their approaches to studying technologies and practices of identification.

#### Investigating the spatial and temporal reach of sociotechnologies of identification

The co-occurence analysis showed that the information systems and technologies are often problematized as part of a 'system', 'regime', 'infrastructure'. This observation resonates with how scholars empirically studying information infrastructures strive to trace and account for the multiple temporal and spatial scales at which systems operate [@hyysaloMethodMattersSocial2019; @karastiStudyingInfrastructuringEthnographically2018]. The question would therefore be of how to localize and study these complex phenomena. One way is through multi-sited ethnography approaches which assume that multiplying the sites of research can be used to give accounts of the connections and detail of distributed phenomena. For example, the 'Mig@Net-Transnational Digital Networks, Migration and Gender' project undertook a multi-sited ethnography approach of European border policies and practices by combining sites and contexts in Europe [@tsianosTransnationalMigrationEmergence2010]. The team of this two-year transdisciplinary research project were able to triangulate observations from different locales (Greece, Germany, Italy) and from various actors (migrants, policy experts). By combining observations regarding the Eurodac system from different sites they could show discrepancies in the categorizations of asylum seekers.

Broadly speaking, the Eurodac system assigns one of three categories to asylum seekers based on if the person (1) applies regularly for internation protection, (2) is found crossing the border illegally, or (3) is found illegally present within a Member State. However, based on interviews with officials in 2011, they found that there exists national and institutional disparities in how these categories are used and interpreted. For instance, at the time, one of their interlocutors in Germany was puzzled about why Greece was mainly using the second but not the third category. This example also shows how method of combining observations from multiple sites can have a politics of counteracting views of borders as impassable and instead highlight inconsistencies and unpredictability of border and migration control.

<!-- This chapter too is written in the context of an interdisciplinary research project using a mix of quantitative of qualitative methods. -->

The method of multi-sited ethnography has traditionally been put forward to bridge distinctions between macro phenomena — lifeworld, regimes, systems, etc. — and local sites [@marcusEthnographyWorldSystem1995]. However, such dichotomies between micro and macro have been widely criticized by other scholars. According to Latour [@latourReassemblingSocialIntroduction2005], and actor-network theory more generally, a priori distinctions between micro and macro should be avoided since 'scale is the actor's own achievement.' (185). Another approach is therefore to "localiz[e] the global" [@latourReassemblingSocialIntroduction2005, p.173] by tracing the 'connections leading from one local interaction to the other places, times, and agencies through which a local site is made to do something' (173).

For instance, @pelizzaIdentificationTranslationArt2021 has traced how requirements for incorporating FBI standards for biometric identification in devices used at the Hellenic border "create trans-national associations with the EU Commission, corporate contractors and the US security regime". @donkoMigrationControlLocal2022 have shown how European migration management technologies for identification moves beyond the external borders of the EU. Through an ethnographic account the authors explain how border posts at the border between Burkina Faso and Niger is connected to EU agencies such as European Border and Coast Guard Agency (Frontex) through border management information systems of the IOM, to capture people's biographic and biometric data. Furthermore, the EU-funded West Africa Police Information System connects these border posts to all member countries of INTERPOL global policing communication system. Avoiding dichotomies of scale therefore makes it possible to observe the emergence of new and different topologies of relations between actors.

The spatial and temporal reach of sociotechnologies of identification does not mean that these technologies are necessarily stable, but rather their enacted across contexts is manifold. @soysurenEuropeanInstrumentsDeportation2022, for instance, took a comparative approach to compare the implementation of the Dublin III regulation (of the Eurodac system) between a founding EU member (France) and an associated country (Switzerland). They found that France took a more sceptical and decentralized approach in the use of the Dublin system for deporting people, whereas Switzerland eagerly took up the system and deployed in a highly centralized manner. In this way, their comparison shows how even a single European instrument can have different meanings and be put differently into practice.

A final point related to the temporal and spatial aspects is how research addressed change across time. First, the under-representation of the biometric aspects of the SISII systems, for instance, showed how research can lag behind, or perhaps understate the evolution of the information systems. Second, there is also a bias towards only focusing on successful projects and not taking into account failures. For example, the project of the second version of the Schengen Information System (SISII), encountered substantial difficulties: 'delays, an escalating budget, political crises and criticisms of the new system's potential impact on fundamental rights' [@parkinDifficultRoadSchengen2011, p.1]. This deficit in research stands in contrast to e-government and information systems literature more broadly, where failures have been long-standing concern due its high stakes and use of public money [@pelizzaBirthFailureConsequences2018].

#### Delineating the ecologies of interlinked actors

The co-occurrence of terms for the kinds of people mentioned in research shows that mainly certain kinds of people are mentioned in the corpus: 'migrant', 'asylum seeker', 'refugee'. The 'Autonomy of Migration' approach, for instance, takes migrants' practices of subverting and appropriating mobility regimes as a starting point and in opposition to the Fortress Europe discourse [@scheelAutonomyMigrationAppropriating2019]. This image of migration and border controls as fortifications has been criticized as favouring a security and control narrative that excludes the multiple practices and experiences of borders and migration [@mezzadraBorderMethodMultiplication2013] and a favours a paternalistic image towards migrants as powerless and in need of aid. By focusing on migrants' experience authors in this scholarship aim to destabilize these tropes by showing migrants' capacities to subvert and get round restrictive mechanisms of migration and border control.

Focus on moments and sites in which various actors interlink and affect each other, in order to arrive at balanced and appropriate accounts of the different actors. A closer look at literature shows that researchers tend to focus on specific actors: from interviews with local administrators and officers of international organizations of migration centres [@pollozekInfrastructuringEuropeanMigration2019], to interviews with officials and experts from European and national institutions [@glouftsiosGoverningCirculationTechnology2018; @trauttmansdorffInfrastructuralExperimentationCollective2021]. Moreover, studies drawing inspiration from STS and ANT also stress the role of non-humans [@pollozekInfrastructuringEuropeanMigration2019].

The multiplicity of places and actors involved, as well as the specialized and closed nature of the work certainly does unfortunately create barriers for researchers. For instance, a report by the 'Advancing Alternative Migration Governance' project explains how the development of the EU information systems 'has been engineered in specialized and closed forums, such as expert workshops, task forces, technical studies, pilots, or advisory groups and technological platforms steering not just policies, but also the formulation of research and development priorities of funding programmes, like the FP7 and Horizon2020' [@jeandesbozFinalReportEntry2020, p.10].  The authors of the report remark that therefore certain aspects, and less visible actors, such as the influence of the 'financial dynamics' have remained under researched.

Next, I reflect on these challenges with some of my own fieldwork findings of a software package that is entangled in identification of people at EU and Member States.

## Biographical moments

In this section I will draw on findings from fieldwork I conducted at the supplier of a software package for matching data for identification in fields of migration, borders, security (WCC). As explained previously, one of the aims of the fieldwork was to trace different episodes of the development and deployments of the data matching software and compare deployments at EU and Member State systems. As such, the research was thought to provide insights into the heterogeneous set of actors involved in practices of identifying and circulating data about people on the move at the European border [@pelizzaProcessingAlterityEnacting2019].

Practically, I joined the company named WCC to investigate the design, use, and evolution of a software product dealing with data matching and data deduplication. As a temporary member of the team, I visited their headquarters in The Netherlands, had access to relevant documentation, carried out individual interviews with people from the company and the customers, and attended some of the team's joint meetings. 

Here, I will focus on the evolution of WCC's software system called the 'ELISE ID platform' (ELISE), deployed at the immigration and naturalization service of the Netherlands and the central system of the EU Visa Information System. The collected data I draw on include (1) field notes, document analysis on the package for data matching, (2) interviews with developers, sales, consultants at the supplier, and (3) participant observations at industry events. For analysing the fieldwork data, I followed standard methods for inductive coding and developing themes.

The ELISE ID platform is also integrated with the systems of the immigration and naturalization service of the Netherlands (Immigratie- en Naturalisatiedienst, hereafter IND). The IND is responsible for, among others, processing the applications from people who want to stay in The Netherlands or who want to become Dutch nationals. Practically speaking, the IND information system leverages the ELISE ID platform to facilitate searching for applicant data against the biographic information in their back-office system and to deal with data issues such as duplicate records.

<!-- Following @glaserBiographyAlgorithmPerforming2021 I structure my findings as biographical moments in the lifecycle of the identity matching software that show the interconnected and contingent aspects of sociotechnologies of identification. -->

## Genealogy/biography of WCC ELISE

### A generic tool for searching and matching data

<!-- ### Spatial and temporal reach of the software package -->

<!-- 
What deficit does it address:

- Evolving across time: upgrades, gaining new features.
- 
 -->

Research has shown how technologies for identifying and controlling people on the move are embedded in local context and practices moulds the meaning and operation of border and migration control [@bigoSecuritizationPracticesThree2014]. Furthermore, authors have noted that such surveillance systems can easily be used for new and derived uses apart from their original objectives [@monahanEmergingPoliticsDHS2009]. This kind of 'function creep' has, for instance, been referred to for the Eurodac biometric identification system. The original purpose of the system was to support the Dublin system for preventing people from making asylum requests in multiple Member States. This scope has gradually been increased by allowing police authorities to query the database, and put forward as an attestation of the linking of migration and crime control (sometimes termed ‘crimmigration’) [@broedersEuropeanBorderSurveillance2011; @amelungCrimmigrationControlBorders2021].

There is a risk that the view that, through situated uses, systems assemble new meanings beyond their original scope assumes that the technologies are the outcome of a rational process of designing and implementing systems by system builders with clear-cut objectives. Instead of a rational process, Information Systems scholars have started to correct this view and brought to the fore the contingent aspects of information systems designs that spans negotiations, adaptations over multiple timescales and between various cross-organizational actors. A genealogical [@gassonGenealogicalStudyBoundaryspanning2006] or biographical approach [@pollockSoftwareOrganisationsBiography2009]....

In the case of the deployments ELISE software package in the VIS and INDIGO systems, tracing the genealogy of the systems shows a surprising lines of progenitors which have left their marks on the software. This pedigree also highlights the translation and generification work needed to transport the software package across contexts and organizations, to eventually end up in those EU and Member State systems. From the early days of the company when it was founded in 1996, the founders thought of the software primarily as a generic database for matching different things. The founding legend told me was that one of the founders came up with the idea after unsatisfactory results while looking for a house. He also knew of other friends having similar issues while searching for a job. Fundamentally, the problem they experienced was that specifying too strict criteria for a search, the number of results plummeted.

The idea and execution for this kind of fuzzy searching and matching engine was therefore twofold. First, the founders realized that there was a need for a searching and matching engine that would always return a result, even with imprecise search criteria. This way realized primarily by reworking the conventional ways of expressing the data matching problem through satisfying Boolean propositions. In the company's software data matching would instead rely on fuzzy logic to a find and rank results based on the probability two data objects would match. Second, the founders anticipated that there would be a need for such software would exist in many more domains besides his trouble of finding a house. Accordingly, the company's first customers came from a broad range of domains; from matching people with houses, people with jobs, wine enthusiasts to wines matching their tastes, people with their ideal holiday booking. The following production description from a 2009 version of their website displays this original:

> ‘[N]o matter how flawed or incomplete the search criteria, ELISE is always able to return a match. Looking for an email that was sent in October about a team meeting? ELISE will find it, even if you got it wrong and the email was sent in September. Searching for a candidate in a 40 km/mile range? ELISE will find the candidate that best fits the criteria, even if they happen to be 48 km/miles away. Even if you have limited knowledge of what you are actually looking for, just a few simple steps with ELISE will provide all of the information you need.’ [^results]

[^results]: <https://web.archive.org/web/20090704023143/http://www.wcc-group.com/page.aspx?menu=solutions&page=solutions>

Briefly stated, the software provides for additional advanced searching and matching of information on existing databases. The novelty of the technology comes from using various kinds of fuzzy logic algorithms to search structured and unstructured data — taking into account that this data may be incomplete or inaccurate. Here, fuzzy logic refers to a form of logic in mathematics where truth variables are calculated in probabilities instead of only being "true" and "false". Consequently, search results are returned as values indicating the probability that two sets of identity data can be considered identical — i.e., match. In the case of matching identity, this always the software to handle the difficulties of matching between personal data from different locales, scripts, cultural contexts, and so forth.

The software for searching and matching identities is thus not only used for practices of identification in migration and border control such as in the Visa Information System. The software has been developed and deployed for use in various domains, one being government agencies involved in identity matching for security. In reality, the company's most important customers are public and private employment services who use the software to match job seekers with vacancies. In this context advanced features such as bi-directional matching are used to, for instance, match a person's job search criteria with the criteria demand by a job announcement. Searching and matching identity data for security contexts, in contrast, is generally only in one direction. That is, compared to a job announcement in a database that specifies who should apply, a person's identity record generally has no demanded requirements to match. Work was therefore required to translate and make generic such data matching across contexts and domains, leading to tensions in the development of the product. Tracing these connections between customers makes it possible to understand how this software company became a subcontractor in the consortium that developed the Visa Information System.

### Advances in the identity and security markets

Let's jump forward in time for a moment to better understand the scale of the Visa Information System. As opposed to the previously mentioned tendency of researchers to focus on biometric identification, identification based on alphanumeric data such as a person's name, date of birth, or nationality should not be underestimated. From the 'Report on the technical function of the Visa Information System (VIS)' [@eu-lisaReportTechnicalFunction2020] we can learn that in 2019, for instance, 17 million visa applications (and hence the data of non-EU citizens) were registered in the central system. Furthemore, alphanumeric searches on this data are a significant factor of identification for the VIS; the report notes 25 million alphanumeric searches which are thus executed through the ELISE search and match software. The high frequency of searches is also visible in the importance given to average response time of searches (less than 0.8 seconds). The report further notes that this response time does not include retrieval of a visa application by its number or visa-sticker number, which has a slightly faster response time. That is, the aforementioned searches would correspond to more ambiguous searches based on other alphanumeric data such as name, date of birth, nationality. Furthermore, the number of data stored keeps increasing and by mid-2018 the licence of the ELISE engine was upgraded to deal with increases in the amount of records. It is clear that for a system such as the VIS a search on, for example, biographic data from a passport is key and that the WCC ELISE software package plays an important role. So how did this modest Dutch data matching company's software of about 50 employees become entangled in a global borders and security infrastructure?

The origins of WCC in the security and identity market can, surprisingly, be found in a successful project for the German public employment service together with the multinational IT information technology services and consulting company Accenture [@rippenSterkePositieHR2006; @betlemUtrechtseDatatechnologieMoet2011]. Based on this positive experience, Accenture invited WCC to get involved in the contract awarded to the consultancy company for the United States Visitor and Immigrant Status Indicator Technology (US-VISIT) system. The US-VISIT program is biometric entry-exit system used to identify and record the arrival and departure of non-U.S. citizens to the United States. The system further performs checks against terrorist, criminal, and immigration watchlists.[add-source] As such, the WCC solution played a role in making biometric (and biographic?) data available for efficiently searching and matching.

Overall, there was a keen interest to get involved in large U.S. government systems for identity management in security and border control. The WCC-founder Peter Went was well aware of the new possible opportunities for the company in the US after the September 11 attacks and the subsequent War on Terror [@@betlemUtrechtseDatatechnologieMoet2011]. Already in 2004 the company was involved with matching of patient records of U.S. healthcare company. A 2009 WCC whitepaper, they detailed how their software could comply with Homeland Security Presidential Directive 24 which establishes a framework for interagency cooperation and interoperability of biographic and biometric data as part of United States counterterrorism efforts and screening processes against Known and Suspected Terrorists (KST) watchlists. The company was furthermore present in annual meetings of the National Defense Industrial Association. And in 2011 they participated [-@WCCWinsTop2011] in the MITRE challenge, a kind of competition to test solutions for matching identity data.

In 2011, the MITRE Corporation, a non-profit research organization for the US federal government, launched a challenge for individuals, companies, and researchers to develop and benchmark the best possible solution for ‘multicultural name matching’. The whole concept was inspired by the famous ‘Netflix prize’, a competition launched by the then still budding streaming company for anyone to submit solutions to improve the accuracy of their movie recommendation system based on a data set made available by the company. Similarly, in the MITRE challenge the organization provided a data set of names (given name, surname) and variations which could be realistically be found in a databases. Participants (academic or government research institutions, commercial companies, individuals) could then use their solution to identify matching names and upload these results on a platform [@millerInternationalMulticulturalName2012].

There were internal disagreements if WCC time could be allocated to participate in the competition. But, a clear incentive to compete was it, if they could do well, then they would be invited to present their solution to the ‘three letter agencies in America’ (Interview): the Federal Bureau of Investigation (FBI), Drug Enforcement Agency (DEA), Central Intelligence Agency (CIA). WCC did in fact score well and achieved one of the three 'Top Tier Vendors' [@WCCWinsTop2011]. Although these favourable results do not seem to have had much succeses in winning contracts with for U.S. government systems, the partnership with Accenture persisted. In 2012 the European Commission selected a consortium of companies, Accenture, Morpho and HP to maintain the EU Visa Information and Biometric Matching Systems which included WCC as a subcontractor.

The first versions of the Visa Information System were progressively deployed in regions of the world. As the system gained more use the capacity of the system needed to increase and a ‘VIS Evolutions’ project was started. One of the goals of this project was ‘to change the search engine to improve its performance.’ [@eu-lisaReportTechnicalFunctioning2013, p.8] A new version of the VIS system was therefore developed through the consortium and under the management of the freshly established European Agency for the Operational Management of Large Scale IT Systems in the Area of Freedom, Security and Justice (eu-LISA). In 2014 a ‘completely new VIS system in terms of infrastructure, software versions and search engine’ was provided, and hence with WCC ELISE as a component to search and match for searches based on alphanumeric data.

However, it is important to note that this VIS Evolutions project was an upgrade of a previously existing system. This detail meant that this project would entail a complex migration for Member States connecting to the central VIS system where everything would need to keep working as usual. In practice then, the configuration ELISE of the central EU-VIS would not be able to use advanced matching features. The interfacing specifications for searching defined for the initial VIS system would need to followed in order to not break the integrations between the central and Member State systems. As such, we can see in this deployment of ELISE in the VIS an example of the instability of the software package. For the VIS, the software did not add any sophisticated identity matching but did provide a remarkable improvement processing power and performance of the system that could support the substantial increases of the usage of the system by Member States’ consular posts [@lisaVISReportPursuant2016].

### Travelling software & data matching knowledge

This focus on the performance stands in contrast with the deployment of the software at the IND. In this case, an entirely new system (INDiGO) was developed which allowed for much more customization and discussions between the supplier and the customer to set up a suitable implementation. For instance, in meeting minutes I had access to I could see ongoing discussions about what could be the rights weights for different search criteria. Furthermore, whenever new features were developed for ELISE, such as with new name matching functionalities developed during the MITRE challenge, these features could be added through software upgrades.

By tracing the lineage of the software package we can see how of identity and name matching knowledge moves across organizations. Examples of new features available for the IND from 2013, after the MITRE challenge and the EU-VIS, include: matching based on the transcription and transliteration of Arabic and Asian names, taking into account 3rd party AKA information (e.g., "“Ahmed the Tall” should match with “Sheikh Ahmed Salim Swedan” and vice versa"). Also even a ‘EU-VIS specific feature‘ named ‘partial’: ‘Wij should match Wijfels’.

These moments of generification of the software package are related to how the software travels between organizations. Over time these new version of the ELISE system were developed with new data matching possibilities. Customers then have a choice to upgrade their current version of the package and receive new updates. In this way, new knowledge and features about data matching could get transported across organizations.

On the other hand, software suppliers also deal with issues when some features cannot easily be transported. This was visible during discussions on a problem with a new version of a component to query and resolve duplicates in the databases of the IND. The question that arose was if a custom-made solution should be built or a more standardized one that could be further sold at other customers. However, the problem faced was the difficulty of defining what can be considered a duplicate identity. Every customer will have its own definition and so the solution would not be easily transferrable. Deduplication is therefore more often considered part of consulting services, instead of as a specific separate software solution.

### Further developments and more interpretative flexibility

* Gartner magic quarter
* Broader push in world market and 'underdeveloped countries': ID4D Identification for development

The partnership with Accenture did not stop at the VIS but further lead also to a subcontractor role with Accenture to provide the solution for searching and matching biographical and biometric data in the UNHCR's Identity Management System. ELISE makes data from multiple sources interop- erable, regardless of the biometrics used or the number of biographic criteria. Identity information from multiple sources is consolidated into a single master identity record

Furthermore, in 2016 Accenture was invited to discuss the implementation of the UNHCR system (Eu-LISA Industry Workshop, June 14th 2016, Strasbourg). This is just one example of these companies performing as 'thought leaders'. In the case of WCC, displays of their data matching expertise can be seen in the sales and pre-sales activities of WCC. For instance, performing their authority in data matching expertise at industry conferences (eu-LISA), or their strategies regarding competitors. In this way, they perform a role in defining future data matching solutions such for the interoperability of EU systems.

For example, in 2019 WCC was invited to present at the eu-LISA annual conference and in the context of a new interoperability architecture for the EU systems. The presentation at the conference focus heavily on the use of the POLE model (People, Object, Location, Event) for data matching and interoperability. This POLE model is a standard data model used by police for representing crimes, people and objects involved. The experience of WCC with the POLE standard can actually be traced back to their work with another customer, the Finnish police. Important to note is that the POLE has influenced the Univeral Messaging Format which will be used in the interoperability framework. In essence, the lesson is that a prerequisite for data matching across different (legacy) systems is to have one standard to match to. Near the end of the presentation, WCC posited their searching and matching solution as a potential use for the Single Search Interface, one of the interoperability components that will use the UMF standard to query all EU databases at once.

In 2020 WCC once more took part in an eu-LISA organized event, the industry round table. While the presentation in 2022 shared many similarities to the one from the previous year (UMF standard and matching on biographic data), there was one crucial difference. Remarkably, in this presentation the software solution was suggested as a possibility for the Common Identity Repository and Mutltiple Identity Repository. The first is a future database that will contain links for an identity to identity data in other systems and using the UMF. The latter is new component should detect duplicate identities in the CIR. These two presentations show the striking interpretative flexibility of the software package.


<!-- Moreover, this challenge shaped the second mentioned moment, as ELISE was updated with new name matching functionalities. -->

<!-- A look at the 'Report on the technical functioning of the Visa Information System (VIS)' [-@eu-lisaReportTechnicalFunction2020] highlights some changes to this system between 2017 and 2019.  In 2018 a series of webinars was organised by the agency to 'enhance best practice implementation and support the most recent developments' (sic, p. 9). One of these webinars dealt with the ELISE search engine, 'introducing available search profiles and how to use them effectively; providing an overview of the scoring and ranking mechanism of search results'. The rather mundane updates show how maintenance, upgrades, training are crucial to the functioning of the data infrastructures. -->

<!-- Such tensions can also be seen in  This stands in contrast with the system at the IND where much more customization and discussions between the supplier and the customer to set up a suitable implementation could happen. -->

<!-- ### Biographical moment #2: Travelling data matching software -->

<!-- 
What deficits does it solve:
  - Technologies evolving accross space
  - Eurocentric or Member State perspective does not take into account global aspects of software development.

-->

<!-- - Evolving across space: moving between organisations -->
<!-- - Evolving across time: upgrades, gaining new features. -->




### Ecologies of interlinked actors — performing and defining data matching

Other important moments in the lifecycle of the package relates to how the company and its employees define and perform data matching expertise and how this feeds into procurement processes. 



Sales pitches for the software package often focus on the vendor-neutrality when comparing their software to other vendors. The company also develops an PNR/API system, which also uses the ELISE for watchlist matching. In sales pitches the company's system is strategically compared against, for example, the United States Automated Targeting System – Global (ATS-G) Programme. My interlocutor described how they explain that while a country might choose to adopt the ATS-G as a PNR/API system, it can be considered a devil's bargain. The ATS-G system is provided free of charge by the US government, but countries in return have to agree to an ongoing data exchange with the US Customs and Border Protection. In this example, we can see political economy of data at work and how countries can become of a global US surveillance network. The software of WCC is, in this case, presented to potential customer of the WCC software as a way to retain control of their data.

## Conclusion

In this article I have explored the question if research on the materiality and performativity of sociotechnologies of identification to be more reflective and explicit of their methodological choices. The co-occurrence analysis and literature review show how there is a tendency for researchers to focus on either theoretical debates about the systems or localist studies of practices of identification. Through the biographical sketches I attempted to show the value of expanding the analytical focus. For instance, by taking into account other actors and moments in the lifecycle of devices that are rarely features, such as software suppliers and their role in processes of procuring or deploying systems. Importantly, the findings show how systems and practices of identification are rarely self-contained; software suppliers circulate and re-use the software packages, influencing practices of identification across many domains and locales.

- Reflection on my own research has a deficit of not including the perspective of those affected by the technology. Links to PC project and multi-sited fieldwork
- Highlight implications for research.
