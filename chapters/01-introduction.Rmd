# Introduction: Understanding identity data matching in transnational security infrastructures {#ch-intro}

\chaptermark{Introduction}

---

> “The message is that there are no “knowns.” There are things we know that we know. There are known unknowns. That is to say there are things that we now know we don't know. But there are also unknown unknowns. There are things we don't know we don't know. So when we do the best we can and we pull all this information together, and we then say well that's basically what we see as the situation, that is really only the known knowns and the known unknowns. And each year, we discover a few more of those unknown unknowns.” [@rumsfeldPressConferenceFormer2002]

---

## Information gaps and blind spots in identification

Former US Secretary of Defense Donald Rumsfeld made this observation in a 2002 press conference, which has since captivated academic and lay audiences alike. In his observation, he distinguished between what he called "known knowns" (i.e., facts that authorities are confident they have) and "known unknowns" (i.e., facts that authorities are aware they do not yet have). But he also pointed out that there are "unknown unknowns" or blind spots that authorities don't know about and don't even realize they don't know. In the context of this chapter, Rumsfeld's idea of "known unknowns" and "unknown unknowns" offers an insightful lens through which to introduce the challenges of identifying people in the context of border security and migration control. Identifying and tracking individuals across national borders is not always straightforward, as data is only sometimes complete or readily available. This raises the question of how authorities can effectually perform the task of identifying individuals despite the presence of incomplete data sets, aliases, or even false identities, as well as how authorities can acknowledge and address the incompleteness of something whose existence is not known.

Rumsfeld's concept of "known unknowns" can be applied to situations where an individual's data is present in a particular database but is not directly linked to their identity data in other systems. These "known unknowns" or "blind spots" can hinder the ability of authorities to identify people fully due to legal, organizational, or technical challenges. One such example of a "known unknown" in identifying people at borders could be an individual with multiple identity data in different databases or systems that have not been linked. For instance, international watch lists contain information on individuals suspected or known to be involved in criminal activities. Individuals on these lists are often listed with multiple known aliases, making it challenging to link all of their identity data together to establish that they may be the same person. To put it differently, authorities already recognize these individuals, but there remain uncertainties regarding their identification. As such, the ambiguity of personal identity data creates a "known unknown" regarding individuals' identities, which can have implications for security and law enforcement purposes.

Similarly, "unknown unknowns" can apply to information that is not only unknown but also unidentifiable through traditional means. In these cases, technology can play a role in detecting — or should we say enacting? — such blind spots by enabling the analysis and correlation of large amounts of identity data. For instance, advanced algorithms and machine learning techniques can detect previously unknown connections and patterns in the data. In their book "Algorithmic Reason", @aradauAlgorithmicReasonNew2022 offers an intriguing case in which two journalists were potentially flagged as persons of interest by a United States security agency using algorithms that detected anomalies in regular data patterns. In the previous case of "known unknowns", individuals may be placed on a watchlist, and it is known that these persons may use different names or identity documents. On the other hand, "unknown unknowns" involve entirely unknown connections and patterns that cannot be readily identified. By connecting various identities and other data and finding patterns, it becomes possible to identify or re-identify someone who is not yet known or of interest to authorities, thus potentially uncovering "unknown unknowns".

The problem of identifying and connecting identity data is not new and has been a challenge for many domains. However, in recent decades, the collection, storage, and analysis of data have been significantly impacted by technological advancements, resulting in vast amounts of personal information being processed [e.g., @borgmanBigDataLittle2015; @kitchinDataRevolutionBig2014]. Hence, one critical development in this context has been the growing of _data matching technology_ to identify individuals across multiple sources [e.g., @harronChallengesAdministrativeData2017]. By comparing and reconciling data, such as name, address, and identification numbers, data matching technology can help identify individuals even in cases where the information is incomplete or inconsistent, such as due to variations in spelling or formatting. Data matching tools are widely deployed in fields where up-to-date information is vital, such as healthcare, finance, and law enforcement [@talburtSpecialIssueEntity2013].

In the healthcare sector, data matching technology is used to match patient data across different systems to ensure accurate patient identification and prevent medical errors [for example, @leeNaturalisticPatientMatching2016; @mccoyMatchingIdentifiersElectronic2013@sauleauMedicalRecordLinkage2005]. Patients' names, birth dates, and social security numbers, among other identifiers, can be used to match and manage patient records across different healthcare systems and databases [@zechMeasuringDegreeUnmatched2016]. In financial intelligence, data matching is used to, among others, detect fraudulent activities and for sanctions compliance. For instance, SWIFT, a global provider of secure financial messaging services, utilizes data matching algorithms to help financial institutions comply with sanctions regulations [@swiftSimplifyComplexWorld2018; @swiftNameScreeningFactsheet2021], allowing them to accurately identify and flag individuals on sanction lists who may use aliases or fraudulent identities to evade detection.

With the increasing collection of personal data such as electronic medical records, financial transactions, or online purchases, data matching technology has become essential for linking and reconciling data across multiple sources. The technology enables organizations to create more detailed and accurate profiles of individuals, contributing to the detection of fraudulent activities, ensuring regulatory compliance, and dealing with the siloed nature of these data sources. Yet, despite the increasing use of data matching technology in various sectors, there is still a lack of understanding of how it shapes the meaning of the things it connects, including identifying data as suspicious and shaping relations between organizations whose data is being matched and connected. This research seeks to contribute to a more nuanced understanding of the role of data matching technology by investigating how it shapes the meaning of data, practices, and the organizations that use it. As a result, it is necessary to begin by recalling the history and applications of matching and linking data and how it has been applied in the specific context of identity data in border security and migration management.

## Connecting the dots: The development of data matching techniques

The use of computing technology to connect personal identity data has a long past that dates back to the early days of punch card technology, even before the existence of database technology, as evident from research such as @dunnRecordLinkage1946's "Record linkage" and @newcombeAutomaticLinkageVital1959's "Automatic linkage of vital records". The term "record linkage" is often used in areas such as public health, epidemiology, and demography to identify and link records that refer to the same real-world person across different datasets. The process of linking data can be beneficial to states in terms of delivering better services to their citizens and facilitating research, such as in the areas of public health [e.g., @jutteAdministrativeRecordLinkage2011] and demographics [e.g., @abbottLargescaleLinkageTotal2015]. Record linkage typically involves matching records based on common attributes such as name, address, date of birth, or social security number to create a comprehensive view of an individual across multiple datasets. Yet, since its inception, record linkage has had to address the challenges posed by fragmented, incomplete, and duplicated information across multiple sources [@newcombeRecordLinkageMaking1962].

The emergence of electronic computers and database technology enabled more sophisticated matching algorithms to be developed, leading to increased adoption in other fields [@batiniObjectIdentification2016; @christenDataMatchingConcepts2012]. As a result, the process of matching data sets and linking records is now referred to by various names depending on the field and context, such as data matching, data linking, data merging, data integration, record linkage, deduplication, or entity resolution, depending on the specific context and application [@christenDataMatchingConcepts2012]. This dissertation will use the term data matching as it is a more general term referring to identifying records in data sets that refer to the same real-world persons (or other entities) and reconciling duplicates or inconsistencies between data sets.

Another concept related to data matching is _schema matching_. Schema matching addresses the challenge of integrating data from multiple sources with different schema structures. Schema matching's importance stems from its capacity to facilitate data integration across disparate data sources, which is frequently required for effective data matching. For example, records referring to the same person may be challenging to identify without knowledge of the underlying schema structure of the datasets being matched, as the same person may be represented differently across different datasets. Therefore, in fields where data is fragmented and dispersed across multiple sources, data matching and schema matching are crucial components of successful data management and integration. While the term "schema matching" will not be used in the dissertation, the idea of how to investigate correspondences between different schema structures that underpin the data will be explored in greater depth.

Over the years, numerous data matching methods and techniques for classifying matches have been devised [@batiniObjectIdentification2016; @christenDataMatchingConcepts2012; @fellegiTheoryRecordLinkage1969; @winklerMatchingRecordLinkage2014]. The following standard data matching methods can be distinguished based on this literature. One of the most basic techniques for identifying matching records is _deterministic matching_, which employs predefined rules or criteria. For example, when two records have the same first name, last name, and date of birth, they are considered a match. Another approach is _probabilistic matching_ which uses statistical algorithms to calculate the probability that two records are a match based on the similarity of their categories of data. If, as in the previous example, two data records have similar but not identical names or dates of birth, the records may still be considered a match based on the probability calculation. Another approach is _rule-based matching_, which can combine deterministic and probabilistic methods to find matches and incorporates expert knowledge or domain-specific rules to increase accuracy. Last but not least, matching techniques based on _machine learning_ are gaining popularity. Such methods employ algorithms that can learn from data to improve accuracy and more easily adapt to new data sources.

While data matching may seem like a technical process, its increasing use and impact on society and individuals mean that it has significant consequences that should not be overlooked. With the growth of the internet and the digitalization of many aspects of modern life, data matching has become even more ubiquitous, with a wide range of actors using these techniques to link data from different sources and gain insights into individuals, their behaviour, and preferences [@clarkeHumanIdentificationInformation1994; @gandySurveillanceSocietyInformation1989; @zuboffBigOtherSurveillance2015]. Furthermore, using data matching algorithms in automated systems can introduce errors and biases, making some people disproportionately the target of surveillance and control [examples: @benjaminRaceTechnologyAbolitionist2019; @eubanksAutomatingInequalityHow2018]. For instance, the German-Lebanese citizen Khalid al-Masri was imprisoned and tortured by the CIA in 2003 after being mistakenly identified as a suspected terrorist with a similar name. Data matching technologies play a crucial role in these processes by allowing for the analysis and correlation of vast amounts of data and determining previously unknown connections in identity data.

Data matching has a long history that had to address the challenges posed by fragmented, incomplete, and duplicated information across multiple sources, with the development of various techniques. However, data matching is not just a technical process that has the potential to discover previously unknown connections but one that can alter the things being connected. These connections can bring about a shift in the meaning of the data, practices, and the organizations that use it. For instance, one could argue that by matching flight passenger data to terrorist watch lists, the identification of a match alters the original intended use of the passenger data, as well as changing the role of airline carriers [see also, @amooreGovernanceRiskDataveillance2005; @duezDifferentViewMaking2012]. In this case, passenger data is no longer just information on individuals travelling on a particular flight, but it now includes an additional layer of suspicion as to whether the individual is a possible security threat. 

As such, it is crucial to understand how data matching technology shapes the meaning of data and practices, including identifying data as suspicious and shaping relationships between organizations whose data is being matched and connected. This research seeks to contribute to a more nuanced understanding of the role of data matching technology by investigating how it shapes the meaning of data, practices, and organizations. Specifically, it explores the use of matching and linking data in the context of identity data in border security and migration management. The following section takes a closer look at how data matching is used in this context by exploring a contemporary example of data matching in migration and border control within the European Union.

## Leveraging data matching for border control

> “In light of the recent terrorist attacks in Europe and the increase in irregular migration in recent years, action needs to be taken to address this risk of information gaps and blind spots. The measures in this proposal [Interoperability of EU information systems for security, border and migration management] will ensure the various systems can exchange data and share information so that authorized bodies and officers have the information they need to strengthen our borders and better protect Europe.” (European Commission, 2017, MEMO_17_5241)

---

> ”Establishing a common repository of data would overcome the current fragmentation in the EU’s architecture of data management for border control and security. This fragmentation is contrary to the data minimization principle, as it results in the same data being stored several times. Where necessary, the common repository would allow for the recognition of connections and provide an overall picture by combining individual data elements stored in different information systems. It would thus address the current knowledge gaps and shed light on blind spots for border guards and police officers.“ [@europeancommissionCommunicationCommissionEuropean2016, p. 18]

---

> “[One of] the four technical components of the proposal [is] a multiple identity detector — this will verify whether the biographical data that is being searched exists in multiple systems, helping to detect multiple identities. It has the dual purpose of ensuring the correct identification of bona fide persons and combating identity fraud.” [@ecFrequentlyAskedQuestions2017]

---

These quotes reveal how data matching is regarded as a critical component in addressing identity issues in migration and border control systems, including the identification of multiple identities. The quotes mentioned above refer to a project linking identity data of EU information systems for security, border, and migration management.[^interop] Presently, each of these EU information systems operates independently from its database and serves a distinct purpose, such as managing asylum requests, processing visa applications, or supporting law enforcement activities. The proposal explicitly identifies a potential risk of information gaps and blind spots because data is not connected. It proposes to address this by connecting and sharing information from those multiple systems. Furthermore, the EC communication stresses the importance of having the information required to strengthen borders and identify potential threats.

[^interop]: The interoperability initiative follows recommendations from the “Highlevel Expert Group on Information Systems and Interoperability” [@europeancommissionCommissionDecision172016] and a new legislative mandate [@europeanunionRegulationEU20182018] for the European Agency for the operational management of large-scale IT systems in the area of freedom, security and justice (eu-LISA). It was split into two proposals due to different legal provisions for regulating (1) borders and visa, and (2) police and judicial cooperation, asylum, and migration [@europeanunionRegulationEU20192019; @europeanunionRegulationEU20192019a].

The second quote describes the need for "establishing a common repository of data", which would "address the current knowledge gaps and shed light on blind spots for border guards and police officers" (p.18). Finally, the third quote describes a component for finding multiple identities that refer to the same person. Fragmentation in the EU's architecture of data management for border control and security is thus portrayed as causing duplicate data storage and leaving border guards and police officers with knowledge gaps and blind spots. According to this logic, the common repository and multiple identity detector components would enable the recognition of connections and provide an overall picture by combining individual data elements stored in different information systems.

The new components in implementing the EU interoperability project are just one example of how the importance of data matching technologies is increasing. The project aims to improve the efficiency and accuracy of EU information systems for mobility and border control  (including Eurodac, SIS, and VIS) by adding new components that enable the matching of biometric data, visa data, and other identity-related information. However, the use of these new components is not just limited to improving the functioning of these systems. They will also be pivotal in implementing new, interlinked forms of identification of individuals who are deemed suspicious based on the links between data sets based on probabilistic, rule-based, or machine learning-based data matching. It is, therefore, crucial to consider how efforts to close information gaps and blind spots in transnational data infrastructure functioning and design may significantly impact identification processes.

Furthermore, the European Commission is not building these systems by itself but increasingly relies on global information technology suppliers and integrators [@lemberg-pedersenPoliticalEconomyEntry2020; @valdiviaNeitherOpaqueTransparent2022]. A research gap exists in understanding how data matching technologies, which are increasingly developed by commercial entities for global use [e.g., @leeseStandardizingSecurityBusiness2018; @lemberg-pedersenPoliticalEconomyEntry2020; @valdiviaNeitherOpaqueTransparent2022; @zureikGovernanceSecurityTechnology2004], operate and influence processes of identification. The international and commercial dimensions of identification technology mean that there is a growing need to examine how the private sector is involved in developing and implementing these standardized technologies. As @pollockSoftwareOrganisationsBiography2009 have noted, criticism of standardized software and focus on how poorly such software adapts to different settings is not a sufficient research perspective. The widespread use of standardized identification software requires to comprehend how such software is created to operate in various contexts, as well.

## Unpacking the challenge of analyzing data matching in transnational data infrastructures

The previous examples demonstrate how identity data matching has developed into an integral part of border and migration control systems to enable the identification and tracking of individuals across different systems and jurisdictions. As such, matching data from national and international sources indicates that identification practices extend beyond the borders of nation-states, highlighting the internationalization of identification. Yet, research on identification has typically concentrated on how states identify people. Data matching technology, however, is illustrative of the global dimensions of identification, which are only apparent when looking beyond the borders of individual nations.

A transnational perspective can thus shift the focus away from the nation-state and onto the various other actors involved in identification. For instance, there is evidence of a gradual shift away from state authorities creating and implementing identification technology to the state purchasing systems created by commercial organizations. Therefore, identification technology is increasingly becoming a commercial product rather than a creation of the state. Yet, not much is known about how these actors developed identity data matching systems and put them to work. Many factors can contribute to this lack of knowledge, including a lack of transparency in developing such systems, limited access to information on their design and operation, and the complexity of the underlying technical processes. Therefore, further research to unpack the design and operation of identity data matching systems can address this knowledge gap.

In light of these challenge, the following section will outline the research problem, aims, and objectives of this study, which seek to unpack the complexities of analyzing data matching in transnational data infrastructure.

### Research problem, aims, and objectives

This research aims to analyze data matching in transnational data infrastructure. It attempts to do so by unpacking some of the complex dynamics surrounding the development, deployment, and use of data matching technologies in border security and migration control. The study aims to empirically investigate data matching technology used for border security to examine its role in transnational security infrastructures. In particular, the dissertation will look into how infrastructure development, security, and internationalization in identification are all intertwined with identity data matching. To accomplish this task, the research needs to contribute to developing effective methodological strategies for analyzing data matching in transnational infrastructures. To achieve these overarching research aims, the study identifies the following specific research objectives.

* To map the theoretical landscape related to internationalization, securitization, and infrastructuring of identification and derive the dissertation's research question for investigating data matching in transnational data infrastructures (Chapter 2).
* To develop a conceptual framework for analyzing data matching in transnational infrastructures using methodological strategy to uncover the embedded and less obvious technical details of matching and linking identity data in infrastructures (Chapter 3).
* To introduce a new method and software tool to analyze the schemas underpinning information systems in population management (Chapter 4).
* To examine the relationship between identity data matching technologies and routine identification practices (Chapter 5).
* To investigate the long-term development of identification systems and building of transnational data infrastructures by identifying crucial moments in their lifecycle to explore how data matching expertise travels and circulates (Chapter 6).

A mixed-methods approach, including case studies, interviews, and document analysis, will be employed to achieve these objectives. In addition, a novel methodology will be used to analyze the schemas that underlie information systems and the relationships between identity data stored by various authorities. The study uses fieldwork data collected from a software company that develops data matching technology to analyze how their technology is used in the EU and member state systems of border control and migration management. Specifically, the study will explore how routine identification is intertwined with data matching technology and how the software package has evolved to be used in identity and security settings. Through the research objectives outlined above, this dissertation seeks to comprehensively analyze the challenges and opportunities presented by data matching in securitizing the European border in transnational contexts. The following section provides an overview of the dissertation's structure, outlining the chapters and their focus.

## Structure of the dissertation

The organization of this dissertation involves an initial mapping of theoretical concepts, followed by the development of a conceptual framework to direct the analysis, and follows with empirical chapters. Chapter 2 starts by mapping theoretical concepts on identification and matching identity data, drawing on literature related to the internationalization and commercialization of identification, the securitization of identification, and the infrastructuring of identification. This chapter lays the groundwork for the subsequent chapters by discussing various theoretical perspectives on matching identity data and the implications of matching identity data for transnational data infrastructures.

Chapter 3 introduces the conceptual framework for analyzing data matching in transnational infrastructures. The framework uses three methodological strategies, "infrastructural inversions," to direct attention to specific facets of data matching. These three strategies are based on comparing data models, analyzing data practices and tracing sociotechnical change. Comparing data models can reveal information collected by various organizations and systems; data practices can show the searching and matching of identity data within and across organizations; sociotechnical change can shed light on the circulation of data matching knowledge, technologies and practices over time and across organizations. The chapter explains how these strategies were used in the dissertation's fieldwork at a software company developing data matching technology. The chapter also describes the methods of data collection and the techniques of data analysis used in the dissertation.

Chapter 4 introduces the "Ontology Explorer" (OE) methodology, a semantic approach and an open-source tool to analyze the data models underlying information systems. The method is specifically designed to compare data models in different formats used by various systems. This chapter explains how it is applied in the dissertation to reveal less visible assumptions and patterns in information systems. Unlike other methods, the OE allows for the systematic comparison of non-homogeneous data formats and enables comparisons of data models across diverse information systems. Therefore, the OE makes it possible to observe how identity data properties influence the creation and circulation of data and the relations between different authorities' data models.

Chapter 5 examines the relationship between technologies for searching and matching identity data and routine bureaucratic identification practices in migration management. The chapter focuses on how a government migration agency searches and matches client data using a specific data matching software package. The chapter introduces the concept of "re-identification" to refer to the process by which clients of bureaucratic procedures are re-identified in data infrastructures at various points in those procedures. The chapter demonstrates the implications of data matching for designing and using information systems in bureaucratic settings in two ways. First, the chapter shifts the usual focus from first registration to re-identification practices across data infrastructures. Second, the chapter's findings demonstrate how the software mediates (re-)identification practices and redistributes competencies through the software's affordances to mitigate data uncertainties.

Chapter 6 looks at the long-term development of identification systems and infrastructures. The chapter proposes two heuristics for selecting crucial moments in the lifecycle of identification technologies. First, it demonstrates how a software package's changing interpretive flexibility allows us to see actors' varying problematizations of identification, such as those related to the securitization of identification. Second, the chapter demonstrates how "gateway moments" make it possible to see the compromises necessary when building identification infrastructures and adapting globally honed technologies to new settings. Together, these chapter's findings shed light on the activities of under-the-radar actors, such as commercial software vendors, whose distribution and reuse of software packages have long-term implications on identification practices and infrastructures in various contexts.

The dissertation concludes in Chapter 7 with a summary of empirical findings, literature contributions, and reflections on the research process. The study contributes to the literature by mapping the theoretical landscape of identity data matching, introducing a conceptual framework for analyzing data matching in transnational infrastructures, proposing new methods for analyzing data matching and using these to examine the relationship between data matching technologies and bureaucratic practices. It also explores the long-term development of identification systems and infrastructures. Finally, the chapter acknowledges the study's limitations and suggests areas for future research. Overall, the dissertation contends that matching identity data is a complex and multifaceted phenomenon that requires a nuanced and interdisciplinary approach to understand how it shapes and is shaped by transnational data infrastructures.
