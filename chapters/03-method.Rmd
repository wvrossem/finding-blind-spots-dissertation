# Methodology and Data Collection {#ch-method}

<!-- ## Introduction -->

This chapter introduces a methodological framework for tracing data matching practices and technologies in transnational security data infrastructures. The analytical framework integrates more technical computer science perspectives and techniques for linking and matching data models and records, with social science perspectives originating in the field of Science and Technology Studies (STS). Government agencies, business, and other organizations certainly give special attention to tasks of finding records in databases that refer to the same person. As these organizations and agencies collect ever more data about people, they may perceive performance benefits of having complete and accurate information about people, or as beneficial to national security. However, the creation, development, and consequences of technologies for accomplishing such tasks is less understood. With the framework that I outline in this chapter I propose to trace such technologies from four different angles: (1) how kinds of information that is collected about people can be compared by looking at different data models, (2) how organizations search and match identity data they collected, (3) how identity data is matched between organizations, and (4) how, simultaneously with matching identity data, data matching technologies and practices travel and evolve across organizations.

## A framework for analysing data matching

The methodological framework I propose in this chapter is thought to examine three aspects of matching identity data, visualized in \@ref(fig:method-axes-visualization) through several axes. The conceptualization roughly follows a relational data model to represent data as tables that model relationships between data. The three axes capture the dimensions of the data are: _data models_, _categories of data_, and _data values_.

_Data models_ (`z`) are abstract models that standardize the kinds of information about people collected by different organizations. An example of a data model would be the schema for data collected about migrants by a government asylum agency. Each data model specifies specific _categories of data_ (`x`) which are collected about people. The categories of data of the asylum agency's data model may include 'name', 'place of birth', 'date of birth'. Finally, there are the actual _data values_ (`y`) in databases for the data model and its associated categories of data. For example, values for the category of data 'place of birth' may be 'Mechelen'.

```{r method-axes-visualization, echo=FALSE, fig.cap="A visualization of the different aspects of data matching examined through the framework.", out.width="100%", fig.asp=.5, fig.align="center"}
knitr::include_graphics("figures/method-axes-visualization.pdf")
```

That being so, I propose to schematize the three facets of data matching as combinations of pairs of these axes. In the Figure, three axes each zoom in on a particular facet of data matching within and between organizations. The first pair, _(data models `z`, categories of data `x`)_ represents the process of identifying semantic similarities and differences between different data models and their category of data (also known as schema matching). For example, the data model of the government agency may contain the category of data 'family name' while another agency's they interact with uses 'surname' as category of data.

A second pair, _(categories of data `x`, data values `y`)_ relates the categories of data to their actual values in databases, which furthermore may not always correspond to the expectations of the data models. Two applications of data matching within organizations and their databases can in this case can be distinguished: real-time data matching and deduplication. Real-time data matching mainly addresses the issue of retrieving information about a person through search queries. For example, police officers may need query databases based on the categories of data 'name', 'nationality', 'date of birth' and to see if approximate matches exists for those personal details. Data matching techniques will therefore be used to find similar matching identities' data, rather than only exact matches. Deduplication, on the other hand, is the use of data matching technologies for identifying records in a database that refer to the same person and fusing the multiple records.

Finally, the pair _(data models `z`, data values `y`)_ intends to address data matching across organizations and agencies. Identity data records that refer to the same person may exist in systems and databases of different organizations and government agencies. Data matching in this case refers to the tasks related to identifying and potentially linking or merging such identity data spread across various databases. A crucial challenge for data matching techniques is due to the fact that unique identifiers are not always available and hence that matching relies on personal information which is not always complete or accurate. Personal information such as names, dates of birth frequently contain typographical errors and variations. For example, a woman may have used her maiden name as surname in one system while information collected in another database uses her husband's surname after marriage. However, the question for us here is how — by bringing such data in relation with each other — data matching practices and technologies shapes the relations between different organizations. The underlying assumption is that such technologies can trigger or even settle controversies about which actors produce more reliable data.

Furthermore, and related to the last pair, is the question of how not only identity data are matched across systems, but also how technologies and practices for data matching travel across organizations. As companies develop tools to support these tasks and deploy them at multiple locations and times, the concomitant knowledge of how to manage typographic errors, name variations, missing data, and so forth also travels across organizations.

To my knowledge no single method could easily be adapted to examine these various facets of data matching within and across organizations. I therefore propose a methodological framework that combines other established methods and perspective that are appropriate for examining each axis.
