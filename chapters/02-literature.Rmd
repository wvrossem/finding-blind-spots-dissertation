# Matching identity data in transnational security infrastructures and beyond {#ch-literature}

## Literature 1 — data and classification studies

## Literature 2 — collaborative work in information infrastructures

## Literature 3 — nexus of user-designer-technology

## A conceptual framework for analysing data matching in distributed settings

Following the overview of existing work and the gaps in their methods, I now put forward a conceptual framework for tracing data matching practices and technologies in transnational security data infrastructures. Such a framework is needed since no single method or theory can easily be adapted to examine these multiple facets of data matching practices and technologies within and across organizations. In this section, I therefore propose a conceptual framework that amalgamate established methods and perspective into one framework that guides the research in examining these multiple facets. The conceptual framework, in essence, integrates more technical computer science perspectives and techniques on linking and matching data models and records, with social science perspectives originating primarily in fields associated with Science and Technology Studies (STS).

As previously said, for government agencies, business, and other organizations the tasks of finding records in databases that refer to the same person can be important in many situations. As such organizations and agencies have been collecting ever more data about people, they may perceive performance benefits of having complete and accurate information about people, or even as beneficial to national security. The techniques to do these kinds of data matching are therefore well established. However, the creation, development, and consequences of deploying technologies for accomplishing such data matching is less well understood. With the framework that I outline in this section I propose to trace data matching practices and technologies as sociotechnical phenomena, and from four different angles: (1) how the kinds of information that is collected about people can be compared by looking at different data models and what this tells about the organizations, (2) how organizations search and match identity data, and which may have quality issues, (3) how such identity data is further matched between organizations, and (4) how, simultaneously with matching identity data, data matching technologies and practices travel and evolve across organizations.

To discuss these different aspects of analysing the matching of identity data, I propose to visualize the framework through several axes (Figure \@ref(fig:method-axes-visualization)). This visualization roughly follows a relational data model to represent data as tables that model relationships between data. The three axes capture the dimensions of the data which are: _data models_, _categories of data_, and _data values_. Next, I will describe how each of these different axes and the relations between them relates to different aspects of data matching within and across organizations.

```{r method-axes-visualization, echo=FALSE, fig.cap="A visualization of the different aspects of data matching examined through the framework.", out.width="100%", fig.asp=.5, fig.align="center"}
knitr::include_graphics("figures/method-axes-visualization.pdf")
```

To begin, the axis for _data models_ (axis `z`) represents the abstract models that standardize the kinds of information about people collected by different organizations. An example of such a data model would be the schemas specifying which data are collected about migrants by a government agency. Each organization might define its own data model, while some might share a data model to make interfacing between systems possible. Each data model specifies _categories of data_ (axis `x`) which are collected about people. For example, the categories of data of the asylum agency's data model may include "name", "place of birth", "date of birth". Finally, there are the actual _data values_ (axis `y`) in the systems' databases for the data model and its associated categories of data. For example, values for the category of data "place of birth" may be "Brussels".

That being so, I propose to schematize the three facets of data matching as combinations of pairs of these axes. In Figure \@ref(fig:method-axes-visualization), these three axes each zoom in on a particular facet of data matching within and across organizations.

### Matching data models

The first pair _(data models `z`, categories of data `x`)_ represents the process of identifying semantic similarities and differences between different data models and their categories of data to support discursively analyse and compare the expectations and imaginaries of diverse actors. For example, the data model of a government agency may contain the category of data "family name" while another agency they interact with uses "surname" as category of data. So while the name of the categories of data are distinct, they clearly refer to a similar concept. In this case, a part of someone's personal name that indicates their family.

This first aspect of matching people's identity data that is addressed by the conceptual framework is therefore the relations between different information systems' data models. That is, how different data models for collecting information about people-on-the-move are situated in relation to one another, and what this tell about the organizations which developed and make use of these models to collect, search, and match identities.

To do this, the method draws, first, on studies of classification and its consequences which have addressed the question of how to retrace the ethical and political work of otherwise mundane devices of representations. Researchers have previously used and combined various makeshift methods — from narrative interviews [@gazanImposingStructuresNarrative2005] to discursive textual analysis [@caswellUsingClassificationConvict2012], from participant observation [@meershoekConstructionEthnicDifferences2011] to archival and genealogical research [@gassonGenealogicalStudyBoundaryspanning2006] — for the ethnographic and historical studies of information systems [@starStepsEcologyInfrastructure1996] and their classifications. However, it is necessary to take an interdisciplinary approach and pay close attention to the technical details of classification, as to avoid only taking into account the effects of classification [@kitchinCodeSpaceSoftware2011].

However, following Geiger and Ribes [-@geigerTraceEthnographyFollowing2011], data models can be considered 'thin' traces: being rather standardized schemas made of categories and values, they are hardly meaningful in themselves. A method to analyse them should therefore consider how to turn them into 'thick' data. On the other hand, given their implementation in diverse infrastructures, data models can be an excellent starting point to understand how geographically distributed sites are connected [@latourReassemblingSocialIntroduction2005]. Burns and Wark [@burnsWhereDatabaseDigital2020] have dubbed such approach "database ethnography" and used traces left behind of a database as a site to analyze how social meanings of phenomena change over time — but, only using their own ad-hoc mix of methods.

On the other hand, this aspect of matching data models shares concerns with methods developed in computer science fields interested in the use of semantic technologies, such as knowledge engineering, linked data, and natural language processing. For example, the relationship between the different types of categories and their variations is closely linked to the outcome of processes known as schema or ontology matching, which finds correspondences between concepts of schemas or ontologies [@euzenatOntologyMatching2007; @kementsietsidisSchemaMatching2009]. Another linked technique called ontology learning aims to automate processes for creating ontologies. These (semi-)automatic mechanisms then include extracting concepts and relationships between concepts from a domain of discourse by analysing a corpus of documents in that domain. There are thus shared concerns about how to examine the way different knowledge representations interrelate, and about how to recover such representations from a discursive domain. Yet, there are fundamental differences which make the methods hard to effectively support a discursive analysis.

Methods of knowledge engineering are generally more concerned with creating technologies that help machines understand better means for the systems, and integrating different sources of information work together. By contrast, the method for this research needs to support discursive analysis by taking differences in representations as a starting point to analyse imaginaries of diverse organizations and authorities and to combine the analysis with ethnographic observation. To address this aspect of data matching there is therefore a need for approaches that can support analyses of formalized data models in two ways. First, to support analyses of information systems which define their own data models, even if these systems are not immediately comparable. Second, to systematically and quantitatively supports discursive analysis of 'thin' data models, also by detecting differences and absences between systems.

### Data matching within organizations

### Data matching across organizations

### Travelling data matching software

